{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "notebook_header"
    ]
   },
   "source": [
    "# `Midterm 2`, `Fall 2022`: `Capturing Data Changes for Slowly Changing Dimensions`\n",
    "_Version 1.0.0_  \n",
    "\n",
    "Version History  \n",
    "\n",
    "1.0.0\n",
    "- Initial release.\n",
    "\n",
    "*All of the header information is important. Please read it..*\n",
    "\n",
    "**Topics, number of exercises:** This problem builds on your knowledge of `working with tabular data`. It has **9** exercises, numbered 0 to **8**. There are **19** available points. However, to earn 100% the threshold is **12** points. (Therefore, once you hit **12** points, you can stop. There is no extra credit for exceeding this threshold.)\n",
    "\n",
    "**Exercise ordering:** Each exercise builds logically on previous exercises, but you may solve them in any order. That is, if you can't solve an exercise, you can still move on and try the next one. Use this to your advantage, as the exercises are **not** necessarily ordered in terms of difficulty. Higher point values generally indicate more difficult exercises. \n",
    "\n",
    "**Demo cells:** Code cells starting with the comment `### define demo inputs` load results from prior exercises applied to the entire data set and use those to build demo inputs. These must be run for subsequent demos to work properly, but they do not affect the test cells. The data loaded in these cells may be rather large (at least in terms of human readability). You are free to print or otherwise use Python to explore them, but we did not print them in the starter code.\n",
    "\n",
    "**Debugging your code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
    "\n",
    "**Exercise point breakdown:**\n",
    "\n",
    "- Exercise 0: **3** point(s)\n",
    "- Exercise 1: **2** point(s)\n",
    "- Exercise 2: **1** point(s)\n",
    "- Exercise 3: **2** point(s)\n",
    "- Exercise 4: **3** point(s)\n",
    "- Exercise 5: **3** point(s)\n",
    "- Exercise 6: **1** point(s)\n",
    "- Exercise 7: **2** point(s)\n",
    "- Exercise 8: **2** point(s)\n",
    "\n",
    "**Final reminders:** \n",
    "\n",
    "- Submit after **every exercise**\n",
    "- Review the generated grade report after you submit to see what errors were returned\n",
    "- Stay calm, skip problems as needed, and take short breaks at your leisure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "topic_intro"
    ]
   },
   "source": [
    "## Scenario (don't dwell on this)\n",
    "\n",
    "You have just been hired by the hot new startup **Spot-i-flix-ify** (this is a fictional company which will offer video and audio streaming services) as a Data Scientist. This is a small startup so you have to \"wear many different hats,\" so to speak. Your first task on the job is to set up their data warehousing so that they can capture a historical record of their operations for analysis later. The operational database (which someone else has already set up) only contains the current state of the operation to maintain maximum efficiency while performing tasks like adding new customers, changing services, applying promotions, etc. It will not contain any history and is not intended have complex queries run against it. \n",
    "  \n",
    "While this is a fictional company and simulation data, **there is a real-world use case** for the processes developed in this notebook.\n",
    "\n",
    "## Data (Don't dwell on this. The structures you are working with will be explained in each exercise.)\n",
    "You are working with four tables:\n",
    "- `customers` - Center of the \"star\" schema. Primary Key: `id`.\n",
    "  - `customers.id` - a unique identifier for an individual customer.\n",
    "  - `customers.paid` - ('True'|'False') - indicates whether a customer has paid their bill for their upcoming month of service.\n",
    "- `prices` - The prices of the services offered by **Spot-i-flix-ify**. Primary Key: `service, tier, promo`\n",
    "  - `prices.service` - Name of the sevice\n",
    "  - `prices.tier` - Tier of the service. A service can be offered in several tiers. Higher tiers give customers more features.\n",
    "  - `prices.promo` - Promotion which can be applied to a service/tier combination to offer a discount to customers.\n",
    "  - `prices.price` - The price of a particular service/tier/promo combination.\n",
    "- `services` - Services which each customer is subscribed. Primary Key: `cust_id, service`; Foreign Keys: `cust_id` references `customers.id`, (`service, tier`) references (`prices.service, prices.tier`)\n",
    "  - `services.cust_id` - id of the customer associated with this subscription.\n",
    "  - `services.service` - name of service associated with this subscription. \n",
    "  - `services.tier` - tier of service associated with a subscription.\n",
    "- `promos` - All promos which a customer has ever used for any service. This historical information is required to prevent customers from using the same promo twice.\n",
    "  - `cust_id` - id of a customer associated with a particular record.\n",
    "  - `service` - service which a customer used a particular promo on.\n",
    "  - `promo` - name of the promo associated with a particular record.\n",
    "  - `time_left` - number of remaining months for which the promo price is applied to a service for the customer. If all promos associated with a `cust_id`/`service` pair have 0 months left. The \"base\" promo is applied to the customer for that service.  \n",
    "\n",
    "\n",
    "## On data types\n",
    "These tables are made available to you in a staging environment as Pandas `DataFrame` objects. **All columns in all of the DataFrames are strings (even the columns where you would expect other data types)**. \n",
    "\n",
    "## On SQL\n",
    "We used Pandas exclusively in developing this exam, however some exercise are solvable using SQL. In the cell below we have included the function `dfs_to_conn` which can be used to create in-memory database connections. If you pass in a dictionary mapping table names to DataFrames, `dfs_to_conn` will return a sqlite 3 connection with all of the data in the DataFrames available under the names given as keys. You are also free to write to the in-memory database by creating tables, inserting/deleting/updating records, etc. Anything that SQLite allows should work!\n",
    "\n",
    "Example:\n",
    "  ```\n",
    "my_df = pd.DataFrame({'A':[1,2,3], 'B': [4,5,6], 'C':['x', 'y', 'z']})\n",
    "print(my_df)\n",
    "#    A  B  C\n",
    "# 0  1  4  x\n",
    "# 1  2  5  y\n",
    "# 2  3  6  z\n",
    "conn = dfs_to_conn({'my_table': my_df})\n",
    "cur = conn.cursor()\n",
    "cur.execute('select A, B, C from my_table')\n",
    "result = cur.fetchall()\n",
    "conn.close() \n",
    "print(result) # list of tuples, each tuple is a row\n",
    "#[(1, 4, 'x'), (2, 5, 'y'), (3, 6, 'z')]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "global_imports"
    ]
   },
   "outputs": [],
   "source": [
    "### Global Imports\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "import pandas as pd\n",
    "import time\n",
    "overall_start = time.time()\n",
    "\n",
    "def dfs_to_conn(conn_dfs, index=False):\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    for table_name, df in conn_dfs.items():\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=index)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "### Exercise 0 - (**3** Points): \n",
    "**Motivation** (Don't dwell on this):  \n",
    "The business logic behind the database requires all promos which a customer has ever participated in be stored in the \"live\" business data in order to prevent a customer from using the same promotion twice. However, for keeping the historical record, the data consumers (i.e. your bosses) are only interested in seeing which promotion is actually being applied to a customer's bill. We need to extract this information from the `promos` table.\n",
    "\n",
    "**Requirements**:  \n",
    "Define `get_active_promos(promos)`. The input `promos` is a DataFrame with columns as described in the `promos` table above. These are the columns/descriptions:  \n",
    "\n",
    "- `cust_id` - id of a single customer.\n",
    "- `service` - a service where the customer has participated in a promo.\n",
    "- `promo` - name of a promo in which a customer has participated for the associated service.  \n",
    "- `time_left` - the time the customer has left on the promo.\n",
    "\n",
    "**Note**: There may be many records in `promos` with the same `cust_id`/`service` combination. However, at most one such record will have a `time_left` value other than `'0'`.\n",
    "\n",
    "Your function should return a new DataFrame, `active_promos` derived from `promos` with the schema outlined below. There should be exactly 1 record in `active_promos` for each unique combination of `cust_id`/`service` found in `promos`.  \n",
    "\n",
    "`active_promos` - the promotion which is actually applied to each customer for a particular service\n",
    "- `'cust_id'` - identifies an individual customer.\n",
    "- `'service'` - identifies a service for which the customer has an active promotion. **The customer may not actually be subscribed to the service!**\n",
    "- `'promo'` - the active promo for the `cust_id`/`service` pair.\n",
    "  - If `'time_left'` is '0' for all records associated with the `cust_id`/`service` pair in `promos`, this column should have a value of `'base'`.\n",
    "  - If there is a record associated with a non-zero `'time_left'`, this column should have the `'promo'` from that record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>promo</th>\n",
       "      <th>service</th>\n",
       "      <th>time_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>promo_1</td>\n",
       "      <td>audio</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>promo_3</td>\n",
       "      <td>audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>base</td>\n",
       "      <td>audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>promo_3</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>promo_1</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>base</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>promo_3</td>\n",
       "      <td>audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>promo_1</td>\n",
       "      <td>audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>base</td>\n",
       "      <td>audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>promo_3</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>promo_1</td>\n",
       "      <td>video</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>base</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id    promo service time_left\n",
       "0        0  promo_1   audio         5\n",
       "1        0  promo_3   audio         0\n",
       "2        0     base   audio         0\n",
       "3        0  promo_3   video         0\n",
       "4        0  promo_1   video         0\n",
       "5        0     base   video         0\n",
       "6        1  promo_3   audio         0\n",
       "7        1  promo_1   audio         0\n",
       "8        1     base   audio         0\n",
       "9        1  promo_3   video         0\n",
       "10       1  promo_1   video         4\n",
       "11       1     base   video         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_promos_ex0 = pd.DataFrame([\n",
    "{'cust_id': '0', 'promo': 'promo_1', 'service': 'audio', 'time_left': '5'},\n",
    "{'cust_id': '0', 'promo': 'promo_3', 'service': 'audio', 'time_left': '0'},\n",
    "{'cust_id': '0', 'promo': 'base', 'service': 'audio', 'time_left': '0'},\n",
    "{'cust_id': '0', 'promo': 'promo_3', 'service': 'video', 'time_left': '0'},\n",
    "{'cust_id': '0', 'promo': 'promo_1', 'service': 'video', 'time_left': '0'},\n",
    "{'cust_id': '0', 'promo': 'base', 'service': 'video', 'time_left': '0'},\n",
    "{'cust_id': '1', 'promo': 'promo_3', 'service': 'audio', 'time_left': '0'},\n",
    "{'cust_id': '1', 'promo': 'promo_1', 'service': 'audio', 'time_left': '0'},\n",
    "{'cust_id': '1', 'promo': 'base', 'service': 'audio', 'time_left': '0'},\n",
    "{'cust_id': '1', 'promo': 'promo_3', 'service': 'video', 'time_left': '0'},\n",
    "{'cust_id': '1', 'promo': 'promo_1',  'service': 'video',  'time_left': '4'},\n",
    "{'cust_id': '1', 'promo': 'base', 'service': 'video', 'time_left': '0'}]\n",
    ")\n",
    "demo_promos_ex0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "  cust_id    promo service\n",
    "0       0  promo_1   audio\n",
    "1       0     base   video\n",
    "2       1     base   audio\n",
    "3       1  promo_1   video\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cust_id    promo service\n",
      "2        0  promo_1   audio\n",
      "5        0     base   video\n",
      "8        1     base   audio\n",
      "11       1  promo_1   video\n"
     ]
    }
   ],
   "source": [
    "### Exercise 0 solution\n",
    "import copy\n",
    "def get_active_promos(promos):\n",
    "    ###\n",
    "    df = promos.copy(deep=True)\n",
    "    \n",
    "    df['time_left'] = df['time_left'].apply(lambda x: int(x))\n",
    "    timeLeftDF = df.query('(time_left)>0')\n",
    "    baseDF = df.query('time_left==0 & promo==\"base\"')\n",
    "    \n",
    "    for i in range(len(baseDF['cust_id'])):\n",
    "        for j in range(len(timeLeftDF['cust_id'])):\n",
    "            if (baseDF.iloc[i]['service'] == timeLeftDF.iloc[j]['service'] and baseDF.iloc[i]['cust_id'] == timeLeftDF.iloc[j]['cust_id']):\n",
    "                baseDF.iloc[i, 1] = timeLeftDF.iloc[j]['promo']\n",
    "    \n",
    "    baseDF = baseDF.drop('time_left', axis=1, inplace=False)\n",
    "    return (baseDF)\n",
    "            \n",
    "    ###\n",
    "    \n",
    "### demo function call\n",
    "print(get_active_promos(demo_promos_ex0))\n",
    "# print(returned_output_vars['output_0'])\n",
    "# print(true_output_vars['output_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 0. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex0",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 5 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex0\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_0', \n",
    "    'func': get_active_promos, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'promos':{\n",
    "            'dtype':'df', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 1 - (**2** Points):  \n",
    "\n",
    "**Motivation** (Don't dwell on this):  \n",
    "To allow for faster updates, the business schema is somewhat normalized. To get the full picture of each service a customer is subscribed to, we have to use the relationships between the keys in each table to piece everything together. For our historical record, the requirement is a little different. We will only add records to the history. Recording the history of each normalized table is not desired as it will require more engineering to piece together. We will instead de-normalize the tables and then record the history of our de-normalized result.\n",
    "\n",
    "**Requirements**:  \n",
    "Define the function `denormalize(customers, services, active_promos, prices)` which takes the DataFrame inputs which have the same structure as those in the introduction and from the result of exercise 0. See the data model diagram for the relationships between the 4 tables. \n",
    "\n",
    "![data_model](schema.png)\n",
    "\n",
    "  Your function should return a DataFrame `df` which contains the following columns:\n",
    "  - `id` - identifies a particular customer (from `customers`)\n",
    "  - `paid` - ('True'|'False') indicating whether the customer `id` has paid their bill (from `customers`)\n",
    "  - `service` - a service which a customer is subscribed. There should be one record for each unique `id`/`service` pair (from `services`)\n",
    "  - `tier` - tier of a service for the `id`/`service` pair. (from `services`)\n",
    "  - `promo` - promo being applied to the `id`/`service` pair. (from `active_promos`)\n",
    "      - Remember that a record existing with a `cust_id`/`service` combination in `active_promos` _does not imply the customer is subscribed to that service_.\n",
    "  - `price` - price charged for the `id`/`service` pair (from `prices`)\n",
    "\n",
    "  You can accomplish this task using a series of \"left\" merges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      "  id   paid\n",
      "0  0   True\n",
      "1  1  False\n",
      "\n",
      "services\n",
      "  cust_id service tier\n",
      "0       0   audio    1\n",
      "1       1   video    1\n",
      "2       1   audio    2\n",
      "\n",
      "active_promos\n",
      "  cust_id service  promo\n",
      "0       0   audio  intro\n",
      "1       0   video   base\n",
      "2       1   audio   base\n",
      "3       1   video  intro\n",
      "\n",
      "prices\n",
      "  service tier  promo  price\n",
      "0   audio    1   base   8.99\n",
      "1   audio    1  intro   5.99\n",
      "2   audio    2   base  12.99\n",
      "3   audio    2  intro   9.99\n",
      "4   video    1   base  10.99\n",
      "5   video    1  intro   8.99\n",
      "6   video    2   base  15.99\n",
      "7   video    2  intro  11.99\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_customers_ex1 = pd.DataFrame({'id': {0: '0', 1: '1'}, 'paid': {0: 'True', 1: 'False'}})\n",
    "demo_active_promos_ex1 = pd.DataFrame({'cust_id': {0: '0', 1: '0', 2: '1', 3: '1'},\n",
    " 'service': {0: 'audio', 1: 'video', 2: 'audio', 3: 'video'},\n",
    " 'promo': {0: 'intro', 1: 'base', 2: 'base', 3: 'intro'}})\n",
    "demo_prices_ex1 = pd.DataFrame(\n",
    "    {'service': {0: 'audio',  1: 'audio',  2: 'audio',  3: 'audio',  4: 'video',  5: 'video',  6: 'video',  7: 'video'},\n",
    "    'tier': {0: '1', 1: '1', 2: '2', 3: '2', 4: '1', 5: '1', 6: '2', 7: '2'},\n",
    "    'promo': {0: 'base', 1: 'intro', 2: 'base', 3: 'intro', 4: 'base', 5: 'intro', 6: 'base', 7: 'intro'},\n",
    "    'price': {0: '8.99', 1: '5.99', 2: '12.99', 3: '9.99', 4: '10.99', 5: '8.99', 6: '15.99', 7: '11.99'}})\n",
    "demo_services_ex1 = pd.DataFrame({'cust_id': {0: '0', 1: '1', 2: '1'},\n",
    " 'service': {0: 'audio', 1: 'video', 2: 'audio'},\n",
    " 'tier': {0: '1', 1: '1', 2: '2'}})\n",
    "\n",
    "print('customers')\n",
    "print(demo_customers_ex1)\n",
    "print()\n",
    "print('services')\n",
    "print(demo_services_ex1)\n",
    "print()\n",
    "print('active_promos')\n",
    "print(demo_active_promos_ex1)\n",
    "print()\n",
    "print('prices')\n",
    "print(demo_prices_ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:  \n",
    "```\n",
    "  id   paid service tier  promo  price\n",
    "0  0   True   audio    1  intro   5.99\n",
    "1  1  False   video    1  intro   8.99\n",
    "2  1  False   audio    2   base  12.99\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id   paid service tier  promo  price\n",
      "0  0   True   audio    1  intro   5.99\n",
      "1  1  False   video    1  intro   8.99\n",
      "2  1  False   audio    2   base  12.99\n"
     ]
    }
   ],
   "source": [
    "### Exercise 1 solution\n",
    "def denormalize(customers, services, active_promos, prices):\n",
    "    ###\n",
    "    df = customers.merge(services, left_on='id', right_on='cust_id', how='inner')\n",
    "    df = df.drop('cust_id', axis=1, inplace=False)\n",
    "    \n",
    "    df = df.merge(active_promos, left_on=['service','id'], right_on=['service', 'cust_id'], how='inner')\n",
    "    df = df.drop('cust_id', axis=1, inplace=False)\n",
    "    \n",
    "    df = df.merge(prices, left_on=['service', 'tier', 'promo'], right_on=['service', 'tier', 'promo'], how='inner')\n",
    "    return df\n",
    "    ###\n",
    "    \n",
    "demo_ex1_output = denormalize(demo_customers_ex1, demo_services_ex1, demo_active_promos_ex1, demo_prices_ex1)\n",
    "print(demo_ex1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 1. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 7 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex1\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_1', \n",
    "    'func': denormalize, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'customers':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'services':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'active_promos':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'prices':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 2 - (**1** Points):   \n",
    "**Motivation** (Don't dwell on this):  \n",
    "The business in interested in determining the revenue generated from its customers (go figure!).  After de-normalizing this is pretty easy to calculate. All we have to do is take the sum of the `price` column!\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "Define the function `get_revenue(df)`.\n",
    "\n",
    "The input `df` is a DataFrame with the same structure as the result from exercise 1. Return the total of the `'price'` column. Recall from the intro that all of the data fields are strings, so you will have to explicitly cast to a `float` before computing the total. **Round the result to 2 decimal places**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id  paid service tier promo  price\n",
      "0  0  True   audio    1  base   8.99\n",
      "1  2  True   video    2  base  15.99\n",
      "2  2  True   audio    2  base  12.99\n",
      "3  3  True   audio    1  base   8.99\n",
      "4  4  True   video    1  base  10.99\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_df_ex2 = pd.DataFrame({'id': {0: '0', 1: '2', 2: '2', 3: '3', 4: '4'},\n",
    " 'paid': {0: 'True', 1: 'True', 2: 'True', 3: 'True', 4: 'True'},\n",
    " 'service': {0: 'audio', 1: 'video', 2: 'audio', 3: 'audio', 4: 'video'},\n",
    " 'tier': {0: '1', 1: '2', 2: '2', 3: '1', 4: '1'},\n",
    " 'promo': {0: 'base', 1: 'base', 2: 'base', 3: 'base', 4: 'base'},\n",
    " 'price': {0: '8.99', 1: '15.99', 2: '12.99', 3: '8.99', 4: '10.99'}})\n",
    "\n",
    "print(demo_df_ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "57.95\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.95\n"
     ]
    }
   ],
   "source": [
    "### Exercise 2 solution\n",
    "def get_revenue(df):\n",
    "    ###\n",
    "    newDF = df.copy(deep=True)\n",
    "    \n",
    "    newDF['price'] = newDF['price'].apply(lambda x: float(x))\n",
    "    total = newDF['price'].sum()\n",
    "    \n",
    "    return total\n",
    "    ###\n",
    "    \n",
    "print(get_revenue(demo_df_ex2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 2. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2",
     "locked": true,
     "points": "1",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 2 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex2\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_2', \n",
    "    'func': get_revenue, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'float',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': True, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise followup"
    ]
   },
   "source": [
    "## Capturing Data Changes (feel free to skip reading this.)\n",
    "\n",
    "We are going to store the history by using \"type-2\" journaling. This process involves scanning the business data periodically and keeping track of the first and last dates which a record existed in a particular form. \n",
    "\n",
    "To do this we rely on the assumption that there is a \"key\" which identifies a particular record in the business data. The key will never change, and it can be either a single column or a combination of multiple columns. In this application it is the `id` and `service` columns. All non-key columns are subject to change. We need multiple versions of the each record, so in our journal we add columns to track the \"effective date\" and the \"expiration date\" of each version. The effective date is when the record first existed in a particular form, and the expiration date is the last date when the record existed in a particular form. By convention, the expiration date for any records which currently exist in the business data (i.e. \"active records\") will be '9999-12-31' (the maximum date that can be represented in YYYY-MM-DD).\n",
    "\n",
    "We update the journal as follows:\n",
    "- Key is found in business data which does not exist in the journal (new record)\n",
    "    - Add the record to the journal with the effective date as the current snapshot date and expiration date as '9999-12-31'.\n",
    "- Non-key columns are changed in the business data for a key which already exists in the journal (changed record)\n",
    "    - Set the expiration date for the active record in the journal to 1 day prior to the current snapshot date.\n",
    "    - Add the current record in the business data to the journal with the effective date as the current snapshot date and expiration date as '9999-12-31'.\n",
    "- A key which has an active record in the journal no longer exists in the business data (deleted record)\n",
    "    - Set the expiration date for the active record in the journal to 1 day prior to the current snapshot date.\n",
    "\n",
    "There will be exactly one record in the journal with a particular key and effective date, and there will be exactly one record with a particular key and expiration date. We can re-create a snapshot of the business data for a particular date in the past by filtering the journal to only include records where that date is inclusively between the effective and expiration dates.\n",
    "\n",
    "The next several exercises will break down the process into digestable bits, so don't feel overwhelmed if you don't fully grasp this concept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 3 - (**2** Points):  \n",
    "**Motivation** (don't dwell on this):  \n",
    "\n",
    "The first task in our journaling process is to identify which records in the existing journal are active and which records are not. We will do so by checking the `'exp_dt'` column. All records with `'9999-12-31'` as their expiration date are considered active. We will be rebuilding the entire journal, so we need to partition the existing journal into active and not-active records and return both parts. The active records will be compared with the business data, and the inactive records will be included in the updated journal without modification. Additionally, on the initial load, there will not be an existing journal, so we will need to create it based on the data being loaded and the desired audit columns.\n",
    "\n",
    "**Requirements**:  \n",
    "Define `partition_journal(df, audit_cols, existing_journal=None)`.\n",
    "\n",
    "- The input `df` is a DataFrame - we do not care about it's structure.\n",
    "- The input `audit_cols` is a `list` of strings. These are the names of audit columns used to track history in the journal. `audit_cols` will always include the strings `'eff_dt'` and `'exp_dt'`.\n",
    "- The optional input `existing_journal` is a DataFrame or `None`.  If `existing_journal` is not `None` it will have all of the columns in `df` and all of the `audit_cols` as its columns.\n",
    "\n",
    "Your function should do the following:\n",
    "- If `existing_journal` is `None`, create an empty DataFrame which has all of the columns in `df` and all of the `audit_cols` as its columns. This empty DataFrame will be used in the subsequent operations.\n",
    "- Create `historical_journal` which is a DataFrame containing all rows of `existing_journal` where `'exp_dt'` is something other than `'9999-12-31'`.\n",
    "- Create `active_journal` which is a DataFrame containing all rows of `existing_journal` where `'exp_dt'` is `'9999-12-31'`.\n",
    "- Return the tuple `(historical_journal, active_journal)` - If the `existing_journal` was newly created these will be two empty DataFrames with all columns present in `df` and all of the `audit_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "  id  paid service tier promo  price\n",
      "0  1  True   audio    1  base   8.99\n",
      "1  2  True   video    2  base  15.99\n",
      "2  2  True   audio    2  base  12.99\n",
      "\n",
      "audit_cols\n",
      "['eff_dt', 'exp_dt']\n",
      "\n",
      "existing_journal\n",
      "     id   paid service tier  promo  price      eff_dt      exp_dt\n",
      "667   0   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
      "668   1   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "669   2   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
      "670   2   True   audio    2  intro   9.99  2018-02-01  2018-07-31\n",
      "671   3   True   video    1  intro   8.99  2018-02-01  2018-07-31\n",
      "672   3   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "673   4   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "9     3  False   video    1   base  10.99  2018-08-01  2018-08-31\n",
      "10    3  False   audio    1   base   8.99  2018-08-01  2018-08-31\n",
      "17    0   True   video    2   base  15.99  2018-08-01  2019-02-28\n",
      "1881  1   True   audio    1   base   8.99  2018-08-01  9999-12-31\n",
      "1882  2   True   video    2   base  15.99  2018-08-01  9999-12-31\n",
      "1883  2   True   audio    2   base  12.99  2018-08-01  9999-12-31\n",
      "1884  4   True   audio    1   base   8.99  2018-08-01  9999-12-31\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_df_ex3 = pd.DataFrame({'id': {0: '1', 1: '2', 2: '2'},\n",
    " 'paid': {0: 'True', 1: 'True', 2: 'True'},\n",
    " 'service': {0: 'audio', 1: 'video', 2: 'audio'},\n",
    " 'tier': {0: '1', 1: '2', 2: '2'},\n",
    " 'promo': {0: 'base', 1: 'base', 2: 'base'},\n",
    " 'price': {0: '8.99', 1: '15.99', 2: '12.99'}})\n",
    "demo_existing_journal_ex3 = pd.DataFrame(\n",
    "    {'id': {667: '0', 668: '1', 669: '2', 670: '2', 671: '3', 672: '3', 673: '4', 9: '3', 10: '3', 17: '0', 1881: '1', 1882: '2', 1883: '2', 1884: '4'},\n",
    "    'paid': {667: 'True', 668: 'True', 669: 'True', 670: 'True', 671: 'True', 672: 'True', 673: 'True', 9: 'False', 10: 'False', 17: 'True', \n",
    "            1881: 'True', 1882: 'True', 1883: 'True', 1884: 'True'},\n",
    "    'service': {667: 'video', 668: 'audio', 669: 'video', 670: 'audio', 671: 'video', 672: 'audio', 673: 'audio', 9: 'video', 10: 'audio', 17: 'video',\n",
    "            1881: 'audio', 1882: 'video', 1883: 'audio', 1884: 'audio'},\n",
    "    'tier': {667: '2', 668: '1', 669: '2', 670: '2', 671: '1', 672: '1', 673: '1', 9: '1', 10: '1', 17: '2', 1881: '1', 1882: '2', 1883: '2', 1884: '1'},\n",
    "    'promo': {667: 'intro', 668: 'intro', 669: 'intro', 670: 'intro', 671: 'intro', 672: 'intro', 673: 'intro', 9: 'base', 10: 'base', 17: 'base', \n",
    "            1881: 'base', 1882: 'base', 1883: 'base', 1884: 'base'},\n",
    "    'price': {667: '11.99', 668: '5.99', 669: '11.99', 670: '9.99', 671: '8.99', 672: '5.99', 673: '5.99', 9: '10.99', 10: '8.99', 17: '15.99', \n",
    "            1881: '8.99', 1882: '15.99', 1883: '12.99', 1884: '8.99'},\n",
    "    'eff_dt': {667: '2018-02-01', 668: '2018-02-01', 669: '2018-02-01', 670: '2018-02-01', 671: '2018-02-01', 672: '2018-02-01', 673: '2018-02-01',\n",
    "            9: '2018-08-01', 10: '2018-08-01', 17: '2018-08-01', 1881: '2018-08-01', 1882: '2018-08-01', 1883: '2018-08-01', 1884: '2018-08-01'},\n",
    "    'exp_dt': {667: '2018-07-31', 668: '2018-07-31', 669: '2018-07-31', 670: '2018-07-31', 671: '2018-07-31', 672: '2018-07-31', 673: '2018-07-31',\n",
    "            9: '2018-08-31', 10: '2018-08-31', 17: '2019-02-28', 1881: '9999-12-31', 1882: '9999-12-31', 1883: '9999-12-31', 1884: '9999-12-31'}})\n",
    "demo_audit_cols_ex3 = ['eff_dt', 'exp_dt']\n",
    "\n",
    "print('df')\n",
    "print(demo_df_ex3)\n",
    "print()\n",
    "print('audit_cols')\n",
    "print(demo_audit_cols_ex3)\n",
    "print()\n",
    "print('existing_journal')\n",
    "print(demo_existing_journal_ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "historical_journal WITH NO existing journal\n",
    "Empty DataFrame\n",
    "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
    "Index: []\n",
    "\n",
    "active_journal WITH NO existing journal\n",
    "Empty DataFrame\n",
    "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
    "Index: []\n",
    "\n",
    "historical_journal WITH existing journal\n",
    "    id   paid service tier  promo  price      eff_dt      exp_dt\n",
    "667  0   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
    "668  1   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
    "669  2   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
    "670  2   True   audio    2  intro   9.99  2018-02-01  2018-07-31\n",
    "671  3   True   video    1  intro   8.99  2018-02-01  2018-07-31\n",
    "672  3   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
    "673  4   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
    "9    3  False   video    1   base  10.99  2018-08-01  2018-08-31\n",
    "10   3  False   audio    1   base   8.99  2018-08-01  2018-08-31\n",
    "17   0   True   video    2   base  15.99  2018-08-01  2019-02-28\n",
    "\n",
    "active_journal WITH existing journal\n",
    "     id  paid service tier promo  price      eff_dt      exp_dt\n",
    "1881  1  True   audio    1  base   8.99  2018-08-01  9999-12-31\n",
    "1882  2  True   video    2  base  15.99  2018-08-01  9999-12-31\n",
    "1883  2  True   audio    2  base  12.99  2018-08-01  9999-12-31\n",
    "1884  4  True   audio    1  base   8.99  2018-08-01  9999-12-31\n",
    "```\n",
    "**Note** - This demo runs your solution two times. The first two DataFrames are the expected result when `exixting_journal` is `None`, and the second two DataFrames are the expected result for the `existing_journal` defined in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "historical_journal WITH NO existing journal\n",
      "Empty DataFrame\n",
      "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
      "Index: []\n",
      "\n",
      "active_journal WITH NO existing journal\n",
      "Empty DataFrame\n",
      "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
      "Index: []\n",
      "\n",
      "historical_journal WITH existing journal\n",
      "    id   paid service tier  promo  price      eff_dt      exp_dt\n",
      "667  0   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
      "668  1   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "669  2   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
      "670  2   True   audio    2  intro   9.99  2018-02-01  2018-07-31\n",
      "671  3   True   video    1  intro   8.99  2018-02-01  2018-07-31\n",
      "672  3   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "673  4   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "9    3  False   video    1   base  10.99  2018-08-01  2018-08-31\n",
      "10   3  False   audio    1   base   8.99  2018-08-01  2018-08-31\n",
      "17   0   True   video    2   base  15.99  2018-08-01  2019-02-28\n",
      "\n",
      "active_journal WITH existing journal\n",
      "     id  paid service tier promo  price      eff_dt      exp_dt\n",
      "1881  1  True   audio    1  base   8.99  2018-08-01  9999-12-31\n",
      "1882  2  True   video    2  base  15.99  2018-08-01  9999-12-31\n",
      "1883  2  True   audio    2  base  12.99  2018-08-01  9999-12-31\n",
      "1884  4  True   audio    1  base   8.99  2018-08-01  9999-12-31\n"
     ]
    }
   ],
   "source": [
    "### Exercise 3 solution\n",
    "def partition_journal(df, audit_cols, existing_journal=None):\n",
    "    ###\n",
    "    totalColumnsLst = list(df.columns) + audit_cols\n",
    "    \n",
    "    if existing_journal is None:\n",
    "        existing_journal = pd.DataFrame(columns=totalColumnsLst)\n",
    "    \n",
    "    historical_journal = existing_journal.query('exp_dt != \"9999-12-31\"')\n",
    "    active_journal = existing_journal.query('exp_dt == \"9999-12-31\"')\n",
    "    \n",
    "    return tuple((historical_journal, active_journal))\n",
    "            \n",
    "    ###\n",
    "    \n",
    "### demo function call\n",
    "new_hist, new_active = partition_journal(demo_df_ex3, demo_audit_cols_ex3)\n",
    "hist, active = partition_journal(demo_df_ex3, demo_audit_cols_ex3, demo_existing_journal_ex3)\n",
    "print('historical_journal WITH NO existing journal')\n",
    "print(new_hist)\n",
    "print()\n",
    "print('active_journal WITH NO existing journal')\n",
    "print(new_active)\n",
    "print()\n",
    "print('historical_journal WITH existing journal')\n",
    "print(hist)\n",
    "print()\n",
    "print('active_journal WITH existing journal')\n",
    "print(active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 3. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex3",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 10 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex3\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_3', \n",
    "    'func': partition_journal, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'audit_cols':{\n",
    "            'dtype':'list', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'existing_journal':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'historical_journal':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'active_journal':{\n",
    "            'index':1,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "        \n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Helper function `drop_rename_sort`\n",
    "\n",
    "### Parameters\n",
    "- `df` - any pandas DataFrame\n",
    "- `drop_pattern` - regular expression pattern\n",
    "- `rename_pattern` - regular expression pattern\n",
    "- `key_cols` - list of strings (all of these strings must be column names of `df`)\n",
    "\n",
    "### Functionality\n",
    "- drop any columns in `df` which match `drop_pattern`\n",
    "- rename any of the remaining columns in `df` to names with the `rename_pattern` removed\n",
    "- sort the rows in the result by the `key_cols` in descending order\n",
    "- re-index the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def drop_rename_sort(df, drop_pattern, rename_pattern, key_cols):\n",
    "    import re\n",
    "    return df\\\n",
    "        .drop(columns=[c for c in df.columns if re.search(drop_pattern, c) is not None])\\\n",
    "        .rename(columns={c: re.sub(rename_pattern, '', c) for c in df.columns})\\\n",
    "        .sort_values(key_cols)\\\n",
    "        .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "     col_0   col_1_x   col_1_y  key_col_0  key_col_1\n",
      "0  val_0_0  val_1_0x  val_1_0y          1          1\n",
      "1  val_0_1  val_1_1x  val_1_1y          0          2\n",
      "2  val_0_2  val_1_2x  val_1_2y          2          4\n",
      "3  val_0_3  val_1_3x  val_1_3y          2          3\n",
      "\n",
      "result - drop \n",
      "     col_0     col_1  key_col_0  key_col_1\n",
      "0  val_0_1  val_1_1y          0          2\n",
      "1  val_0_0  val_1_0y          1          1\n",
      "2  val_0_3  val_1_3y          2          3\n",
      "3  val_0_2  val_1_2y          2          4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "    {'col_0': 'val_0_0', 'col_1_x':'val_1_0x', 'col_1_y':'val_1_0y', 'key_col_0':1, 'key_col_1':1},\n",
    "    {'col_0': 'val_0_1', 'col_1_x':'val_1_1x', 'col_1_y':'val_1_1y', 'key_col_0':0, 'key_col_1':2},\n",
    "    {'col_0': 'val_0_2', 'col_1_x':'val_1_2x', 'col_1_y':'val_1_2y', 'key_col_0':2, 'key_col_1':4},\n",
    "    {'col_0': 'val_0_3', 'col_1_x':'val_1_3x', 'col_1_y':'val_1_3y', 'key_col_0':2, 'key_col_1':3}\n",
    "])\n",
    "print('df')\n",
    "print(df)\n",
    "drop_x = drop_rename_sort(df, '_x$', '_y$', ['key_col_0', 'key_col_1'])\n",
    "print()\n",
    "print(\"result - drop \")\n",
    "print(drop_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 4 - (**3** Points): \n",
    "**Motivation** (don't dwell on this):  \n",
    "The next task is to determine which keys exist in both the active partition of the journal and the business data as well as which keys exist in only one or the other. Then we need to partition the business data into two parts (records with keys already in the journal and records without keys in the journal). We also need to partition the active journal data into two parts (records with keys existing in the business data and records without keys existing in the business data). \n",
    "  \n",
    "**Requirements**:  \n",
    "Define the function `compare_to_journal(df, key_cols, active_journal)`.\n",
    "\n",
    "The inputs are as follows:\n",
    "- `df` - a DataFrame.\n",
    "- `active_journal` - another DataFrame. It will have all of the columns which are in `df`, but it may have additional columns. This input may be an empty DataFrame having 0 records.\n",
    "- `key_cols` - a list of strings denoting some columns in `df` and `active_journal`. We can uniquely identify one record in either `df` or `active_journal` by a combination of these columns. \n",
    "\n",
    "Your function should do the following:\n",
    "\n",
    "- \"Outer merge\" `df` and `active_journal` on the `key_cols`. Take a look at the `indicator` and `suffixes` parameters in the [docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html). Let's call the result `merged`.\n",
    "- Partition the rows in `merged` into these 3 partitions. The `indicator` parameter of `merge` will add an extra column to the result which is useful for this task. If you add it, it will need to be removed from the partitions.:\n",
    "    - all rows in `merged` with keys existing only in `df`. Let's call this partition `df_only`.\n",
    "    - all rows in `merged` with keys existing only in `active_journal`. Let's call this partition `aj_only`.\n",
    "    - all rows in `merged` with keys existing in both `df` and `active_journal`. Let's call this partition `both`.\n",
    "- Make **copies** of slices taken from the partitions as follows. The `suffixes` parameter of `merge` adds suffixes to duplicate column names to indicate where each came from. The provided helper function `drop_rename_sort` can be used to perform the heavy lifting here. These DataFrames are what should be returned.\n",
    "    - `new_df` - all columns from `df_only` which **are not** duplicate columns originating from `active_journal`.\n",
    "    - `expired_df` - all columns from `aj_only` which **are not** duplicate columns originating from `df`.\n",
    "    - `compare_new_df` - all columns from `both` which **are not** duplicate columns originating from `active_journal`.\n",
    "    - `compare_old_df` - all columns from `both` which **are not** duplicate columns originating from `df`.\n",
    "\n",
    "\n",
    "The newly created DataFrames should be returned as a tuple, i.e. `return (new_df, expired_df, compare_new_df, compare_old_df)`.\n",
    "\n",
    "All newly created DataFrames should be sorted lexographically based on `key_cols`.\n",
    "\n",
    "Any suffixes or indicator columns added in the `merge` should not be included in the returned results. In other words, all 4 returned DataFrames should have the same column _names_ as `active_journal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "         some_data_col        some_key_col\n",
      "0       some_new_value             new_key\n",
      "1   some_changed_value        existing_key\n",
      "2  other_changed_value  other_existing_key\n",
      "\n",
      "active_journal\n",
      "          some_data_col        some_key_col      eff_dt      exp_dt\n",
      "0        expiring_value        expiring_key  0001-01-01  9999-12-31\n",
      "1  other_previous_value  other_existing_key  0001-01-01  9999-12-31\n",
      "2   some_previous_value        existing_key  6040-01-01  9999-12-31\n",
      "\n",
      "key_cols\n",
      "['some_key_col']\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_df_ex4 = pd.DataFrame([\n",
    "    {'some_data_col':'some_new_value', 'some_key_col': 'new_key'},\n",
    "    {'some_data_col':'some_changed_value', 'some_key_col': 'existing_key'},\n",
    "    {'some_data_col':'other_changed_value', 'some_key_col': 'other_existing_key'}\n",
    "])\n",
    "\n",
    "demo_active_journal_ex4 = pd.DataFrame([\n",
    "    {'some_data_col':'expiring_value', 'some_key_col': 'expiring_key', 'eff_dt': '0001-01-01', 'exp_dt':'9999-12-31'},\n",
    "    {'some_data_col':'other_previous_value', 'some_key_col': 'other_existing_key', 'eff_dt': '0001-01-01', 'exp_dt':'9999-12-31'},\n",
    "    {'some_data_col':'some_previous_value', 'some_key_col': 'existing_key', 'eff_dt': '6040-01-01', 'exp_dt':'9999-12-31'}\n",
    "])\n",
    "\n",
    "demo_key_cols_ex4 = ['some_key_col']\n",
    "\n",
    "print('df')\n",
    "print(demo_df_ex4)\n",
    "print()\n",
    "print('active_journal')\n",
    "print(demo_active_journal_ex4)\n",
    "print()\n",
    "print('key_cols')\n",
    "print(demo_key_cols_ex4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "new_df\n",
    "    some_data_col some_key_col eff_dt exp_dt\n",
    "0  some_new_value      new_key    NaN    NaN\n",
    "\n",
    "expired_df\n",
    "    some_data_col  some_key_col      eff_dt      exp_dt\n",
    "0  expiring_value  expiring_key  0001-01-01  9999-12-31\n",
    "\n",
    "compare_new_df\n",
    "         some_data_col        some_key_col      eff_dt      exp_dt\n",
    "0   some_changed_value        existing_key  6040-01-01  9999-12-31\n",
    "1  other_changed_value  other_existing_key  0001-01-01  9999-12-31\n",
    "\n",
    "compare_old_df\n",
    "          some_data_col        some_key_col      eff_dt      exp_dt\n",
    "0   some_previous_value        existing_key  6040-01-01  9999-12-31\n",
    "1  other_previous_value  other_existing_key  0001-01-01  9999-12-31\n",
    "```\n",
    "**Note**: The `key_cols` and non-key columns may be something different than what are used in this demo. The demo names were chosen to make it clear which columns are keys and which columns are non-keys along with the effective date and expiration date.\n",
    "\n",
    "The intermediate values from the demo should be the following if you set the `indicator` to add the extra column and `suffixes` to add `'_df'` and `'_aj'` suffixes to duplicate column names from `df` and `active_journal` respectively.\n",
    "\n",
    "\n",
    "```\n",
    "merged\n",
    "      some_data_col_df        some_key_col      some_data_col_aj      eff_dt      exp_dt      _merge \n",
    "0       some_new_value             new_key                   NaN         NaN         NaN   left_only\n",
    "1   some_changed_value        existing_key   some_previous_value  6040-01-01  9999-12-31        both\n",
    "2  other_changed_value  other_existing_key  other_previous_value  0001-01-01  9999-12-31        both \n",
    "3                  NaN        expiring_key        expiring_value  0001-01-01  9999-12-31  right_only\n",
    "\n",
    "df_only\n",
    "  some_data_col_df some_key_col some_data_col_aj eff_dt exp_dt\n",
    "0   some_new_value      new_key              NaN    NaN    NaN\n",
    "\n",
    "aj_only\n",
    "  some_data_col_df  some_key_col some_data_col_aj      eff_dt      exp_dt\n",
    "3              NaN  expiring_key   expiring_value  0001-01-01  9999-12-31\n",
    "\n",
    "both\n",
    "      some_data_col_df        some_key_col      some_data_col_aj      eff_dt      exp_dt\n",
    "1   some_changed_value        existing_key   some_previous_value  6040-01-01  9999-12-31\n",
    "2  other_changed_value  other_existing_key  other_previous_value  0001-01-01  9999-12-31\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_df\n",
      "    some_data_col some_key_col eff_dt exp_dt\n",
      "0  some_new_value      new_key    NaN    NaN\n",
      "\n",
      "expired_df\n",
      "   some_key_col   some_data_col      eff_dt      exp_dt\n",
      "0  expiring_key  expiring_value  0001-01-01  9999-12-31\n",
      "\n",
      "compare_new_df\n",
      "         some_data_col        some_key_col      eff_dt      exp_dt\n",
      "0   some_changed_value        existing_key  6040-01-01  9999-12-31\n",
      "1  other_changed_value  other_existing_key  0001-01-01  9999-12-31\n",
      "\n",
      "compare_old_df\n",
      "         some_key_col         some_data_col      eff_dt      exp_dt\n",
      "0        existing_key   some_previous_value  6040-01-01  9999-12-31\n",
      "1  other_existing_key  other_previous_value  0001-01-01  9999-12-31\n"
     ]
    }
   ],
   "source": [
    "### Exercise 4 solution\n",
    "\n",
    "#         Make copies of slices taken from the partitions as follows. The suffixes parameter of merge adds suffixes to\n",
    "#         duplicate column names to indicate where each came from. The provided helper function drop_rename_sort can be \n",
    "#         used to perform the heavy lifting here. These DataFrames are what should be returned.\n",
    "\n",
    "#         new_df - all columns from df_only which are not duplicate columns originating from active_journal.\n",
    "#         expired_df - all columns from aj_only which are not duplicate columns originating from df.\n",
    "#         compare_new_df - all columns from both which are not duplicate columns originating from active_journal.\n",
    "#         compare_old_df - all columns from both which are not duplicate columns originating from df.\n",
    "\n",
    "# The newly created DataFrames should be returned as a tuple, i.e. return (new_df, expired_df, compare_new_df, compare_old_df).\n",
    "\n",
    "# All newly created DataFrames should be sorted lexographically based on key_cols.\n",
    "\n",
    "# Any suffixes or indicator columns added in the merge should not be included in the returned results. In other words, all 4 returned DataFrames should have the same column names as active_journal.\n",
    "def compare_to_journal(df, key_cols, active_journal):\n",
    "    ###\n",
    "#    print(list(df.columns))\n",
    "    merged = df.merge(active_journal, on=key_cols, indicator=True, how='outer')\n",
    "#     print(merged)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "    df_only = merged.query('_merge == \"left_only\"')\n",
    "    df_only = df_only.drop('_merge', axis=1, inplace=False)\n",
    "#     print(df_only)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "    aj_only = merged.query('_merge == \"right_only\"')\n",
    "    aj_only = aj_only.drop('_merge', axis=1, inplace=False)    \n",
    "#     print(aj_only)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "    both = merged.query('_merge == \"both\"')\n",
    "    both = both.drop('_merge', axis=1, inplace=False)\n",
    "#     print(both)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "#     print(list(active_journal.columns))\n",
    "    \n",
    "    new_df = drop_rename_sort(df_only, '_y$', '_x$', key_cols)\n",
    "    expired_df = drop_rename_sort(aj_only, '_x$', '_y$', key_cols)\n",
    "    compare_new_df = drop_rename_sort(both, '_y$', '_x$', key_cols)\n",
    "    compare_old_df = drop_rename_sort(both, '_x$', '_y$', key_cols)\n",
    "#     print(new_df)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "#     print(expired_df)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "#     print(compare_new_df)\n",
    "#     print(\"--------------------------------------------------------------------------------------\")\n",
    "#     print(compare_old_df)\n",
    "\n",
    "    return tuple((new_df, expired_df, compare_new_df, compare_old_df))\n",
    "    ###\n",
    "    \n",
    "### demo function call\n",
    "demo_new_df, demo_expired_df, _demo_compare_new_df, demo_compare_old_df = compare_to_journal(demo_df_ex4, demo_key_cols_ex4, demo_active_journal_ex4)\n",
    "print('new_df')\n",
    "print(demo_new_df)\n",
    "print()\n",
    "print('expired_df')\n",
    "print(demo_expired_df)\n",
    "print()\n",
    "print('compare_new_df')\n",
    "print(_demo_compare_new_df)\n",
    "print()\n",
    "print('compare_old_df')\n",
    "print(demo_compare_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 4. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 11 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex4\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_4', \n",
    "    'func': compare_to_journal, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'key_cols':{\n",
    "            'dtype':'list', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'active_journal':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'new_df':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'expired_df':{\n",
    "            'index':1,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'compare_new_df':{\n",
    "            'index':2,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'compare_old_df':{\n",
    "            'index':3,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 5 - (**3** Points): \n",
    "**Motivation** (don't dwell on this):  \n",
    "Our next task is to identify records which have changed and which records are unchanged. These are a subset of records having keys in both the business data and the active journal. We need to partition both the business data and journal data into two parts based on whether the data has changed.\n",
    "\n",
    "**Requirements**:  \n",
    "Define `compare_changes(compare_new_df, compare_old_df, audit_cols)`.\n",
    "\n",
    "The inputs are as follows:\n",
    "\n",
    "- `compare_new_df` - a DataFrame\n",
    "- `compare_old_df` - another DataFrame with the same columns/shape/indexing as `compare_new_df`\n",
    "- `audit_cols` - a list of column names which should not be used for comparison.\n",
    "\n",
    "You can assume that the rows `compare_new_df` and `compare_old_df` are sorted and indexed such that they can be compared directly.\n",
    "\n",
    "- Identify the columns in `compare_new_df` which are not in `audit_cols`. Let's call this `cols`.\n",
    "- Compare the values in `compare_new_df[cols]` with the values in `compare_old_df[cols]`.\n",
    "- Return these 3 new DataFrames:\n",
    "    - `unchanged` - All of the rows in `compare_new_df`  where **all** values are the same in the comparison.  \n",
    "    - `old_changed` - All of the rows in `compare_old_df` where there are **any** differences in the comparison.\n",
    "    - `new_changed` - All of the rows in `compare_new_df` where there are **any** differences in the comparison.\n",
    "\n",
    "It is possible that `compare_new_df` and `compare_old_df` are **both** empty DataFrames. If this is the case all 3 returned DataFrames would also be empty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_new_df\n",
      "  some_column   key_column audit_column_1 audit_column_2\n",
      "0   new_val_0    changed_0           None           None\n",
      "1   new_val_1    changed_1           None           None\n",
      "2  same_val_0  unchanged_0           None           None\n",
      "3  same_val_1  unchanged_1           None           None\n",
      "4   new_val_2    changed_2           None           None\n",
      "5  same_val_2  unchanged_2           None           None\n",
      "\n",
      "compare_old_df\n",
      "  some_column   key_column audit_column_1 audit_column_2\n",
      "0   old_val_0    changed_0            foo            bar\n",
      "1   old_val_1    changed_1            foo            bar\n",
      "2  same_val_0  unchanged_0            foo            bar\n",
      "3  same_val_1  unchanged_1            foo            bar\n",
      "4   old_val_2    changed_2            foo            bar\n",
      "5  same_val_2  unchanged_2            foo            bar\n",
      "\n",
      "audit_cols\n",
      "['audit_column_1', 'audit_column_2']\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_compare_new_df_ex5 = pd.DataFrame([\n",
    "    {'some_column': 'new_val_0', 'key_column': 'changed_0', 'audit_column_1': None, 'audit_column_2': None},\n",
    "    {'some_column': 'new_val_1', 'key_column': 'changed_1', 'audit_column_1': None, 'audit_column_2': None},\n",
    "    {'some_column': 'same_val_0', 'key_column': 'unchanged_0', 'audit_column_1': None, 'audit_column_2': None},\n",
    "    {'some_column': 'same_val_1', 'key_column': 'unchanged_1', 'audit_column_1': None, 'audit_column_2': None},\n",
    "    {'some_column': 'new_val_2', 'key_column': 'changed_2', 'audit_column_1': None, 'audit_column_2': None},\n",
    "    {'some_column': 'same_val_2', 'key_column': 'unchanged_2', 'audit_column_1': None, 'audit_column_2': None}\n",
    "])\n",
    "\n",
    "demo_compare_old_df_ex5 = pd.DataFrame([\n",
    "    {'some_column': 'old_val_0', 'key_column': 'changed_0', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
    "    {'some_column': 'old_val_1', 'key_column': 'changed_1', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
    "    {'some_column': 'same_val_0', 'key_column': 'unchanged_0', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
    "    {'some_column': 'same_val_1', 'key_column': 'unchanged_1', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
    "    {'some_column': 'old_val_2', 'key_column': 'changed_2', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
    "    {'some_column': 'same_val_2', 'key_column': 'unchanged_2', 'audit_column_1': 'foo', 'audit_column_2': 'bar'}\n",
    "])\n",
    "\n",
    "demo_audit_cols_ex5 = ['audit_column_1', 'audit_column_2']\n",
    "\n",
    "print('compare_new_df')\n",
    "print(demo_compare_new_df_ex5)\n",
    "print()\n",
    "print('compare_old_df')\n",
    "print(demo_compare_old_df_ex5)\n",
    "print()\n",
    "print('audit_cols')\n",
    "print(demo_audit_cols_ex5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:  \n",
    "```\n",
    "unchanged\n",
    "  some_column   key_column audit_column_1 audit_column_2\n",
    "2  same_val_0  unchanged_0           None           None\n",
    "3  same_val_1  unchanged_1           None           None\n",
    "5  same_val_2  unchanged_2           None           None\n",
    "\n",
    "old_changed\n",
    "  some_column key_column audit_column_1 audit_column_2\n",
    "0   old_val_0  changed_0            foo            bar\n",
    "1   old_val_1  changed_1            foo            bar\n",
    "4   old_val_2  changed_2            foo            bar\n",
    "\n",
    "new_changed\n",
    "  some_column key_column audit_column_1 audit_column_2\n",
    "0   new_val_0  changed_0           None           None\n",
    "1   new_val_1  changed_1           None           None\n",
    "4   new_val_2  changed_2           None           None\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unchanged\n",
      "  some_column   key_column audit_column_1 audit_column_2\n",
      "2  same_val_0  unchanged_0           None           None\n",
      "3  same_val_1  unchanged_1           None           None\n",
      "5  same_val_2  unchanged_2           None           None\n",
      "\n",
      "old_changed\n",
      "  some_column key_column audit_column_1 audit_column_2\n",
      "0   old_val_0  changed_0            foo            bar\n",
      "1   old_val_1  changed_1            foo            bar\n",
      "4   old_val_2  changed_2            foo            bar\n",
      "\n",
      "new_changed\n",
      "  some_column key_column audit_column_1 audit_column_2\n",
      "0   new_val_0  changed_0           None           None\n",
      "1   new_val_1  changed_1           None           None\n",
      "4   new_val_2  changed_2           None           None\n"
     ]
    }
   ],
   "source": [
    "### Exercise 5 solution\n",
    "def compare_changes(compare_new_df, compare_old_df, audit_cols):\n",
    "    ###\n",
    "    # Handle the case of empty DataFrame inputs\n",
    "    if compare_new_df.shape[0] == 0:\n",
    "        compare_new_df.copy(), compare_new_df.copy(), compare_new_df.copy() # 3 empty DataFrames with proper colunms\n",
    "    \n",
    "    # Identify all columns which are not `audit_cols`\n",
    "    cols = [c for c in compare_new_df.columns if c not in audit_cols]\n",
    "    \n",
    "    # Create boolean mask - True when there is any difference between the two frames, ignoring `audit_cols`\n",
    "    different = (compare_new_df[cols] != compare_old_df[cols]).any(axis=1)\n",
    "    \n",
    "    # Use the mask to partition the DataFrames and return result\n",
    "    unchanged = compare_new_df.loc[~different, :]\n",
    "    old_changed = compare_old_df.loc[different, :]\n",
    "    new_changed = compare_new_df.loc[different, :]\n",
    "    return (unchanged,\n",
    "           old_changed,\n",
    "           new_changed)\n",
    "    ###\n",
    "\n",
    "# Run demo of function    \n",
    "(demo_unchanged_ex5,\n",
    "demo_old_changed_ex5,\n",
    "demo_new_changed_ex5) = compare_changes(demo_compare_new_df_ex5, demo_compare_old_df_ex5, demo_audit_cols_ex5)\n",
    "print('unchanged')\n",
    "print(demo_unchanged_ex5)\n",
    "print()\n",
    "print('old_changed')\n",
    "print(demo_old_changed_ex5)\n",
    "print()\n",
    "print('new_changed')\n",
    "print(demo_new_changed_ex5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 5. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex5",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 8 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex5\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_5', \n",
    "    'func': compare_changes, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'compare_new_df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'compare_old_df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'audit_cols':{\n",
    "            'dtype':'list', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'unchanged':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'old_changed':{\n",
    "            'index':1,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        },\n",
    "        'new_changed':{\n",
    "            'index':2,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 6 - (**1** Points): \n",
    "**Motivation** (Don't dwell on this):\n",
    "So far we have sliced and diced the business data and journal data into several partitions. Some of these partitions will need to be added to the journal by setting the effective and expiration dates. Here we will write a generic function to set the effective date to the \"data date\" (date when the snapshot was taken) and set the expiration date to '9999-12-31' for an arbitrary partition.\n",
    "  \n",
    "**Requirements**:\n",
    "Define `add_records(df, data_date)`  \n",
    "\n",
    "The input `df` is a DataFrame which can be assumed to have columns `'eff_dt'` and `'exp_dt'`. The input `data_date` is a Pandas Timestamp object. The function should return a _new_ DataFrame having the same data as `df` with the following exceptions:\n",
    "- The `'eff_dt'` field should be set to the `data_date` as a string in 'YYYY-MM-DD' format for all records. See the [docs](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html) for more information on performing this transformation.\n",
    "- The `'exp_dt'` field should be set to `'9999-12-31'` for all records.\n",
    "\n",
    "**Note** `df` may be empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "  eff_dt exp_dt    col0   col1\n",
      "0   None   None  val_00  val01\n",
      "1   None   None  val_10  val11\n",
      "2   None   None  val_20  val21\n",
      "\n",
      "data_date\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "2020-10-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_df_ex6 = pd.DataFrame([\n",
    "    {'eff_dt':None, 'exp_dt':None, 'col0':'val_00', 'col1':'val01'},\n",
    "    {'eff_dt':None, 'exp_dt':None, 'col0':'val_10', 'col1':'val11'},    \n",
    "    {'eff_dt':None, 'exp_dt':None, 'col0':'val_20', 'col1':'val21'},        \n",
    "])\n",
    "print('df')\n",
    "print(demo_df_ex6)\n",
    "print()\n",
    "demo_data_date_ex6 = pd.to_datetime('2020-10-15')\n",
    "print('data_date')\n",
    "print(type(demo_data_date_ex6))\n",
    "print(demo_data_date_ex6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:  \n",
    "```\n",
    "       eff_dt      exp_dt    col0   col1\n",
    "0  2020-10-15  9999-12-31  val_00  val01\n",
    "1  2020-10-15  9999-12-31  val_10  val11\n",
    "2  2020-10-15  9999-12-31  val_20  val21\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       eff_dt      exp_dt    col0   col1\n",
      "0  2020-10-15  9999-12-31  val_00  val01\n",
      "1  2020-10-15  9999-12-31  val_10  val11\n",
      "2  2020-10-15  9999-12-31  val_20  val21\n"
     ]
    }
   ],
   "source": [
    "### Exercise 6 solution\n",
    "def add_records(df, data_date):\n",
    "    ###\n",
    "    \n",
    "    newDF = df.copy(deep=True)\n",
    "    newDF['exp_dt'] = '9999-12-31'\n",
    "    newDF['eff_dt'] = data_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return newDF\n",
    "    ###\n",
    "    \n",
    "    \n",
    "### demo function call\n",
    "print(add_records(demo_df_ex6, demo_data_date_ex6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 6. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex6",
     "locked": true,
     "points": "1",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 1 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex6\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_6', \n",
    "    'func': add_records, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'data_date':{\n",
    "            'dtype':'Timestamp',\n",
    "            'check_modified':False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 7 - (**2** Points): \n",
    "**Motivation** (Don't dwell on this):\n",
    "So far we have sliced and diced the business data and journal data into several partitions. Some of these partitions will need to be expired in the journal by updating the expiration dates. Here we will write a generic function to set the expiration date to one day prior to the \"data date\" (date when the snapshot was taken).  \n",
    "  \n",
    "**Requirements**:\n",
    "Define `expire_records(df, data_date)`  \n",
    "\n",
    "The input `df` is a DataFrame which can be assumed to have columns `'eff_dt'` and `'exp_dt'`. The input `data_date` is a Pandas Timestamp object. The function should return a _new_ DataFrame having the same data as `df` with the following exceptions:\n",
    "- The `'exp_dt'` field should be set to **one day prior to the** `data_date` as a string in 'YYYY-MM-DD' format for all records. See the [stackoverflow](https://stackoverflow.com/questions/28954093/how-to-add-subtract-time-hours-minutes-etc-from-a-pandas-dataframe-index-wh) or [pandas docs](https://pandas.pydata.org/docs/user_guide/timeseries.html) for more information on math with Timestamps and [strftime docs](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html) for more information on extracting the string.  \n",
    "\n",
    "You will want to use a module that accounts for changes in months, years, and leap-days for calculating the `exp_dt`.  \n",
    "\n",
    "**Note** - `df` may be empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "       eff_dt exp_dt    col0   col1\n",
      "0  0001-01-01   None  val_00  val01\n",
      "1  0001-01-01   None  val_10  val11\n",
      "2  0001-01-01   None  val_20  val21\n",
      "\n",
      "data_date\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "2020-03-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_df_ex7 = pd.DataFrame([\n",
    "    {'eff_dt':'0001-01-01', 'exp_dt':None, 'col0':'val_00', 'col1':'val01'},\n",
    "    {'eff_dt':'0001-01-01', 'exp_dt':None, 'col0':'val_10', 'col1':'val11'},    \n",
    "    {'eff_dt':'0001-01-01', 'exp_dt':None, 'col0':'val_20', 'col1':'val21'},        \n",
    "])\n",
    "print('df')\n",
    "print(demo_df_ex7)\n",
    "print()\n",
    "demo_data_date_ex7 = pd.to_datetime('2020-03-01')\n",
    "print('data_date')\n",
    "print(type(demo_data_date_ex7))\n",
    "print(demo_data_date_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:  \n",
    "```\n",
    "       eff_dt      exp_dt    col0   col1\n",
    "0  0001-01-01  2020-02-29  val_00  val01\n",
    "1  0001-01-01  2020-02-29  val_10  val11\n",
    "2  0001-01-01  2020-02-29  val_20  val21\n",
    "```\n",
    "<!-- Include any shout outs here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       eff_dt      exp_dt    col0   col1\n",
      "0  0001-01-01  2020-02-29  val_00  val01\n",
      "1  0001-01-01  2020-02-29  val_10  val11\n",
      "2  0001-01-01  2020-02-29  val_20  val21\n"
     ]
    }
   ],
   "source": [
    "### Exercise 7 solution\n",
    "def expire_records(df, data_date):\n",
    "    ###\n",
    "    newdf = df.copy(deep=True)\n",
    "    # Subtract a day\n",
    "    newDate = data_date - pd.Timedelta(days=1)\n",
    "    newDate = newDate.strftime('%Y-%m-%d')\n",
    "    newdf['exp_dt'] = newDate\n",
    "    return newdf\n",
    "    ###\n",
    "    \n",
    "### demo function call\n",
    "print(expire_records(demo_df_ex7, demo_data_date_ex7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 7. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex7",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This test executed in 1 seconds\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex7\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_7', \n",
    "    'func': expire_records, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'df':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'data_date':{\n",
    "            'dtype':'Timestamp',\n",
    "            'check_modified':False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise followup"
    ]
   },
   "source": [
    "## Putting it all together\n",
    "(Don't dwell on this)  \n",
    "With the functions we wrote in the past few exercises, we have everything we need to perform a type 2 journaling operation. Here's how it looks all put together:\n",
    "\n",
    "```\n",
    "def journal(df, key_cols, data_date, existing_journal=None):\n",
    "    audit_cols = ['eff_dt', 'exp_dt']\n",
    "    historical_journal, active_journal = partition_jrnl(df, audit_cols, existing_journal)\n",
    "    new_df, expired_df, compare_new_df, compare_old_df = compare_to_journal(df, key_cols, active_journal)\n",
    "    unchanged, old_changed, new_changed = compare_changes(compare_new_df, compare_old_df, audit_cols)\n",
    "\n",
    "    new_records = add_records(new_df, data_date)\n",
    "    new_changed_records = add_records(new_changed, data_date)\n",
    "    expired_records = expire_records(expired_df, data_date)\n",
    "    old_changed_records = expire_records(old_changed, data_date)\n",
    "\n",
    "    return pd.concat([\n",
    "        historical_journal,\n",
    "        new_records,\n",
    "        new_changed_records,\n",
    "        expired_records,\n",
    "        old_changed_records,\n",
    "        unchanged\n",
    "    ])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 8 - (**2** Points): \n",
    "**Motivation** (don't dwell on this):  \n",
    "Here's where all of the tedious work we did partitioning these DataFrames pays off. We can reconstruct a snapshot of any particular date from the journal! To do so we just filter the journal to keep only records whose effective date is on or before that date and whose expiration date is on or after that date.  \n",
    "\n",
    "**Requirements**:\n",
    "Define the function `time_travel(journal, data_date)` as follows:\n",
    "\n",
    "The input `journal` is a DataFrame with columns `'eff_dt'` and `'exp_dt'` in addition other arbitrary columns. The input `data_date` is a string representing a date in 'YYYY-MM-DD' format. The function should return a _new_ DataFrame containing all records where `'eff_dt'` $\\le$ `'data_date'` $\\le$ `'exp_dt'`. \n",
    "\n",
    "The `'eff_dt'` and `'exp_dt'` fields should not be included in the result.\n",
    "\n",
    "**Note**: One convenient fact about storing dates as strings in 'YYYY-MM-DD' format is that you can compare the strings directly with `<`, `<=`, `!=`, `==`, `>=`, `>` without converting to a more complicated data type!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal\n",
      "       id   paid service tier  promo  price      eff_dt      exp_dt\n",
      "674    10   True   video    1  intro   8.99  2018-02-01  2018-07-31\n",
      "675    10   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
      "2057   10   True   video    1   base  10.99  2018-08-01  2019-07-31\n",
      "2058   10   True   audio    1   base   8.99  2018-08-01  2019-07-31\n",
      "1307  998   True   video    1  intro   8.99  2018-12-01  2019-05-31\n",
      "1308  998   True   audio    1  intro   5.99  2018-12-01  2019-05-31\n",
      "1003  998   True   video    1   base  10.99  2019-06-01  2019-09-30\n",
      "1004  998   True   audio    1   base   8.99  2019-06-01  2019-09-30\n",
      "1163   10   True   video    2   base  15.99  2019-08-01  9999-12-31\n",
      "1164   10   True   audio    2   base  12.99  2019-08-01  9999-12-31\n",
      "10    998  False   video    1   base  10.99  2019-10-01  2019-10-31\n",
      "11    998  False   audio    1   base   8.99  2019-10-01  2019-10-31\n"
     ]
    }
   ],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_journal_ex8 = pd.DataFrame(\n",
    "    {'id': {674: '10', 675: '10', 2057: '10', 2058: '10', 1307: '998', 1308: '998', 1003: '998', 1004: '998', 1163: '10', 1164: '10', 10: '998', 11: '998'}, \n",
    "    'paid': {674: 'True', 675: 'True', 2057: 'True', 2058: 'True', 1307: 'True', 1308: 'True', 1003: 'True', 1004: 'True', 1163: 'True', 1164: 'True', \n",
    "            10: 'False', 11: 'False'}, \n",
    "    'service': {674: 'video', 675: 'audio', 2057: 'video', 2058: 'audio', 1307: 'video', 1308: 'audio', 1003: 'video', 1004: 'audio', 1163: 'video', \n",
    "            1164: 'audio', 10: 'video', 11: 'audio'}, \n",
    "    'tier': {674: '1', 675: '1', 2057: '1', 2058: '1', 1307: '1', 1308: '1', 1003: '1', 1004: '1', 1163: '2', 1164: '2', 10: '1', 11: '1'}, \n",
    "    'promo': {674: 'intro', 675: 'intro', 2057: 'base', 2058: 'base', 1307: 'intro', 1308: 'intro', 1003: 'base', 1004: 'base', 1163: 'base', \n",
    "            1164: 'base', 10: 'base', 11: 'base'}, \n",
    "    'price': {674: '8.99', 675: '5.99', 2057: '10.99', 2058: '8.99', 1307: '8.99', 1308: '5.99', 1003: '10.99', 1004: '8.99', 1163: '15.99', \n",
    "        1164: '12.99', 10: '10.99', 11: '8.99'}, \n",
    "    'eff_dt': {674: '2018-02-01', 675: '2018-02-01', 2057: '2018-08-01', 2058: '2018-08-01', 1307: '2018-12-01', 1308: '2018-12-01', \n",
    "            1003: '2019-06-01', 1004: '2019-06-01', 1163: '2019-08-01', 1164: '2019-08-01', 10: '2019-10-01', 11: '2019-10-01'}, \n",
    "    'exp_dt': {674: '2018-07-31', 675: '2018-07-31', 2057: '2019-07-31', 2058: '2019-07-31', 1307: '2019-05-31', 1308: '2019-05-31', \n",
    "            1003: '2019-09-30', 1004: '2019-09-30', 1163: '9999-12-31', 1164: '9999-12-31', 10: '2019-10-31', 11: '2019-10-31'}})\n",
    "print('journal')\n",
    "print(demo_journal_ex8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "data_date: 2018-02-02\n",
    "     id  paid service tier  promo price\n",
    "674  10  True   video    1  intro  8.99\n",
    "675  10  True   audio    1  intro  5.99\n",
    "\n",
    "data_date: 2018-08-01\n",
    "      id  paid service tier promo  price\n",
    "2057  10  True   video    1  base  10.99\n",
    "2058  10  True   audio    1  base   8.99\n",
    "\n",
    "data_date: 2019-01-01\n",
    "       id  paid service tier  promo  price\n",
    "2057   10  True   video    1   base  10.99\n",
    "2058   10  True   audio    1   base   8.99\n",
    "1307  998  True   video    1  intro   8.99\n",
    "1308  998  True   audio    1  intro   5.99\n",
    "\n",
    "data_date: 2019-06-15\n",
    "       id  paid service tier promo  price\n",
    "2057   10  True   video    1  base  10.99\n",
    "2058   10  True   audio    1  base   8.99\n",
    "1003  998  True   video    1  base  10.99\n",
    "1004  998  True   audio    1  base   8.99\n",
    "```\n",
    "\n",
    "**Note** - this demo runs your solution for several different `data_date` values. Each of the DataFrames displayed is from a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_date: 2018-02-02\n",
      "     id  paid service tier  promo price\n",
      "674  10  True   video    1  intro  8.99\n",
      "675  10  True   audio    1  intro  5.99\n",
      "\n",
      "data_date: 2018-08-01\n",
      "      id  paid service tier promo  price\n",
      "2057  10  True   video    1  base  10.99\n",
      "2058  10  True   audio    1  base   8.99\n",
      "\n",
      "data_date: 2019-01-01\n",
      "       id  paid service tier  promo  price\n",
      "2057   10  True   video    1   base  10.99\n",
      "2058   10  True   audio    1   base   8.99\n",
      "1307  998  True   video    1  intro   8.99\n",
      "1308  998  True   audio    1  intro   5.99\n",
      "\n",
      "data_date: 2019-06-15\n",
      "       id  paid service tier promo  price\n",
      "2057   10  True   video    1  base  10.99\n",
      "2058   10  True   audio    1  base   8.99\n",
      "1003  998  True   video    1  base  10.99\n",
      "1004  998  True   audio    1  base   8.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Exercise 8 solution\n",
    "def time_travel(journal, data_date):\n",
    "    ###\n",
    "    newDF = journal.copy(deep=True)\n",
    "    newDF['data_date'] = data_date\n",
    "    newDF = newDF.query(\"eff_dt <= data_date <= exp_dt\")\n",
    "    newDF = newDF.drop([\"eff_dt\", 'data_date', \"exp_dt\"], axis=1, inplace=False)\n",
    "    return newDF\n",
    "    ###\n",
    "    \n",
    "### demo function call\n",
    "for demo_data_date_ex8 in ['2018-02-02', '2018-08-01', '2019-01-01', '2019-06-15']:\n",
    "    print(f'data_date: {demo_data_date_ex8}')\n",
    "    print(time_travel(demo_journal_ex8, demo_data_date_ex8))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 8. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex8",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed! Please submit.\n",
      "This test executed in 5 seconds\n",
      "The exam executed in 8755 seconds\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex8\n",
    "exercise_start = time.time()\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_8', \n",
    "    'func': time_travel, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'journal':{\n",
    "            'dtype':'pd.DataFrame', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'data_date':{\n",
    "            'dtype':'str',\n",
    "            'check_modified':False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'pd.DataFrame',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resource/asnlib/publicdata/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')\n",
    "exercise_end = time.time()\n",
    "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
    "overall_end = exercise_end\n",
    "print(f\"The exam executed in {(pd.to_datetime(overall_end, unit='s') - pd.to_datetime(overall_start, unit='s')).seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "fin"
    ]
   },
   "source": [
    "**Fin.** If you have made it this far, congratulations on completing the exam. **Don't forget to submit!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
